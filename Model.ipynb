{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ec51d80",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5770be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "import sagemaker\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f288244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import s3_folders\n",
    "\n",
    "unbalanced = s3_folders.unbalanced\n",
    "underSample = s3_folders.underSample\n",
    "overSample = s3_folders.overSample\n",
    "combined = s3_folders.combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a53fb3",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b9c19",
   "metadata": {},
   "source": [
    "The model will be defined and trained using the data uploaded to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08135ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Our current execution role is required when creating the model as the training\n",
    "# and inference code will need to access the model artifacts.\n",
    "role = get_execution_role()\n",
    "\n",
    "session = sagemaker.Session() # Store the current SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to retrieve the location of the container which is provided by Amazon for using XGBoost.\n",
    "# As a matter of convenience, the training and inference code both use the same container.\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "container = retrieve(framework = 'xgboost',region = session.boto_region_name, version = \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a34af",
   "metadata": {},
   "source": [
    "## 1. Unbalanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0736cbb5",
   "metadata": {},
   "source": [
    "We set the version variable for it will help us with file management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6367686",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"unbalanced\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1723e41a",
   "metadata": {},
   "source": [
    "Here we load the location of the files on S3 that were uploaded for this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_location = unbalanced[\"test\"] #the information is loaded from the .py file created in the data preparation step\n",
    "val_location = unbalanced[\"val\"]\n",
    "train_location = unbalanced[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix (which folder will we use)\n",
    "prefix = f'twitter_sentiment_{version}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6084f978",
   "metadata": {},
   "source": [
    "### Set the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1510de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a SageMaker estimator object for our model.\n",
    "xgb_unbalanced = sagemaker.estimator.Estimator(container, # The location of the container we wish to use\n",
    "                                    role,                                    # What is our current IAM Role\n",
    "                                    instance_count=1,                  # How many compute instances\n",
    "                                    instance_type='ml.m4.xlarge',      # What kind of compute instances\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "# And then set the algorithm specific parameters.\n",
    "xgb_unbalanced.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb0815",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb192cf7",
   "metadata": {},
   "source": [
    "Set the training and validation data set on s3 to be used by sagemaker. This variables will let the model know where to find the information in S3 that will be used to estimate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26930f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_unbalanced.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac8e11",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b3b72",
   "metadata": {},
   "source": [
    "For this part of the process a transformer object will be created. This is an object can be understood as a function that used the artifacts (betas) created by the model and then uses them to predict based in a new data set. \n",
    "The test dataset will be given to the transformer and the results will be compared to the actual labels that were reserved for the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a transformer object. This will use the artifacts created by the estimator to transform (create a prediction) using the testing dataset.\n",
    "xgb_unbalanced_transformer = xgb_unbalanced.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f295d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_unbalanced_transformer.transform(test_location, content_type='text/csv', split_type='Line') \n",
    "#the location of the test set is passed to the transfomer to perform the transformation. (predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44bf31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_unbalanced_transformer.wait() #we wait until the transformer is done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7befed40",
   "metadata": {},
   "source": [
    "After the tranformation is done, we will specify a new folder where the results (the are created in a S3 folder) can be downloaded from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"results_{version}\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e92c7",
   "metadata": {},
   "source": [
    "Next, using the next command we download the predictions made by the transformer object into the local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbeeba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $xgb_unbalanced_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618fe94",
   "metadata": {},
   "source": [
    "Now the predictions are read with pandas into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None) #the header is none because the first line is a prediction and not the name of the column\n",
    "predictions = [round(num) for num in predictions.squeeze().values] #we convert the predictions to a list so it will be easier to compare with metrics with the real label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bce902",
   "metadata": {},
   "source": [
    "Then we read the labels that were reserved in the data preparation in a local folder for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = pd.read_csv(f\"data_prepared_{version}/test_y.csv\",header = None) \n",
    "test_y = list(test_y[0]) #we transform the first column (not index) to a list so it will be compared with the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0696d9",
   "metadata": {},
   "source": [
    "Now the results are compared by creating a confusion matrix out of the predictions vs the real labels. \n",
    "From the confusion matrix we can calculate the metric for classfication models. We use the tools in the sklearn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(test_y, predictions, labels=None, sample_weight=None, normalize=None)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels')\n",
    "ax.set_title(f'Confusion Matrix. Model : {version}')\n",
    "ax.xaxis.set_ticklabels(['Normal', 'Violent'])\n",
    "ax.yaxis.set_ticklabels(['Normal', 'Violent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print(f\"Model version: {version}\")\n",
    "print(\"Accuracy: \", accuracy_score(test_y, predictions))\n",
    "print(\"Precision: \", precision_score(test_y, predictions))\n",
    "print(\"Recall: \", recall_score(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28098e96",
   "metadata": {},
   "source": [
    "## 2. UnderSampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3851f61",
   "metadata": {},
   "source": [
    "We set the version variable for it will help us with file management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"underSample\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80235924",
   "metadata": {},
   "source": [
    "Here we load the location of the files on S3 that were uploaded for this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f02646",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_location = underSample[\"test\"] #the information is loaded from the .py file created in the data preparation step\n",
    "val_location = underSample[\"val\"]\n",
    "train_location = underSample[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aaa582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix (which folder will we use)\n",
    "prefix = f'twitter_sentiment_{version}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc5c85",
   "metadata": {},
   "source": [
    "### Set the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a SageMaker estimator object for our model.\n",
    "xgb_underSample = sagemaker.estimator.Estimator(container, # The location of the container we wish to use\n",
    "                                    role,                                    # What is our current IAM Role\n",
    "                                    instance_count=1,                  # How many compute instances\n",
    "                                    instance_type='ml.m4.xlarge',      # What kind of compute instances\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "# And then set the algorithm specific parameters.\n",
    "xgb_underSample.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a23bc",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759f2ee",
   "metadata": {},
   "source": [
    "Set the training and validation data set on s3 to be used by sagemaker. This variables will let the model know where to find the information in S3 that will be used to estimate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfda9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f8f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_underSample.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27395bcd",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b586fc5",
   "metadata": {},
   "source": [
    "For this part of the process a transformer object will be created. This is an object can be understood as a function that used the artifacts (betas) created by the model and then uses them to predict based in a new data set. \n",
    "The test dataset will be given to the transformer and the results will be compared to the actual labels that were reserved for the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7197d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a transformer object. This will use the artifacts created by the estimator to transform (create a prediction) using the testing dataset.\n",
    "xgb_underSample_transformer = xgb_underSample.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e83f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_underSample_transformer.transform(test_location, content_type='text/csv', split_type='Line') \n",
    "#the location of the test set is passed to the transfomer to perform the transformation. (predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_underSample_transformer.wait() #we wait until the transformer is done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4cd51",
   "metadata": {},
   "source": [
    "After the tranformation is done, we will specify a new folder where the results (the are created in a S3 folder) can be downloaded from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37093c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"results_{version}\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a7812d",
   "metadata": {},
   "source": [
    "Next, using the next command we download the predictions made by the transformer object into the local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcfffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $xgb_underSample_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b12da7",
   "metadata": {},
   "source": [
    "Now the predictions are read with pandas into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None) #the header is none because the first line is a prediction and not the name of the column\n",
    "predictions = [round(num) for num in predictions.squeeze().values] #we convert the predictions to a list so it will be easier to compare with metrics with the real label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44664bb",
   "metadata": {},
   "source": [
    "Then we read the labels that were reserved in the data preparation in a local folder for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e4f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = pd.read_csv(f\"data_prepared_{version}/test_y.csv\",header = None) \n",
    "test_y = list(test_y[0]) #we transform the first column (not index) to a list so it will be compared with the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e4f4f",
   "metadata": {},
   "source": [
    "Now the results are compared by creating a confusion matrix out of the predictions vs the real labels. \n",
    "From the confusion matrix we can calculate the metric for classfication models. We use the tools in the sklearn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9bc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(test_y, predictions, labels=None, sample_weight=None, normalize=None)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecaa60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels')\n",
    "ax.set_title(f'Confusion Matrix. Model : {version}')\n",
    "ax.xaxis.set_ticklabels(['Normal', 'Violent'])\n",
    "ax.yaxis.set_ticklabels(['Normal', 'Violent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print(f\"Model version: {version}\")\n",
    "print(\"Accuracy: \", accuracy_score(test_y, predictions))\n",
    "print(\"Precision: \", precision_score(test_y, predictions))\n",
    "print(\"Recall: \", recall_score(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2808e37",
   "metadata": {},
   "source": [
    "## 3. OverSampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d95e80",
   "metadata": {},
   "source": [
    "We set the version variable for it will help us with file management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"overSample\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b092177",
   "metadata": {},
   "source": [
    "Here we load the location of the files on S3 that were uploaded for this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba8b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_location = overSample[\"test\"] #the information is loaded from the .py file created in the data preparation step\n",
    "val_location = overSample[\"val\"]\n",
    "train_location = overSample[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix (which folder will we use)\n",
    "prefix = f'twitter_sentiment_{version}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e3aaa",
   "metadata": {},
   "source": [
    "### Set the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164150d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a SageMaker estimator object for our model.\n",
    "xgb_overSample = sagemaker.estimator.Estimator(container, # The location of the container we wish to use\n",
    "                                    role,                                    # What is our current IAM Role\n",
    "                                    instance_count=1,                  # How many compute instances\n",
    "                                    instance_type='ml.m4.xlarge',      # What kind of compute instances\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "# And then set the algorithm specific parameters.\n",
    "xgb_overSample.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ab39e8",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b83e4",
   "metadata": {},
   "source": [
    "Set the training and validation data set on s3 to be used by sagemaker. This variables will let the model know where to find the information in S3 that will be used to estimate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_overSample.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a0ad6",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d0a14",
   "metadata": {},
   "source": [
    "For this part of the process a transformer object will be created. This is an object can be understood as a function that used the artifacts (betas) created by the model and then uses them to predict based in a new data set. \n",
    "The test dataset will be given to the transformer and the results will be compared to the actual labels that were reserved for the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a transformer object. This will use the artifacts created by the estimator to transform (create a prediction) using the testing dataset.\n",
    "xgb_overSample_transformer = xgb_overSample.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc7279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_overSample_transformer.transform(test_location, content_type='text/csv', split_type='Line') \n",
    "#the location of the test set is passed to the transfomer to perform the transformation. (predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_overSample_transformer.wait() #we wait until the transformer is done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ce3bae",
   "metadata": {},
   "source": [
    "After the tranformation is done, we will specify a new folder where the results (the are created in a S3 folder) can be downloaded from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceceec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"results_{version}\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418ee9b0",
   "metadata": {},
   "source": [
    "Next, using the next command we download the predictions made by the transformer object into the local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $xgb_overSample_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec89af1",
   "metadata": {},
   "source": [
    "Now the predictions are read with pandas into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None) #the header is none because the first line is a prediction and not the name of the column\n",
    "predictions = [round(num) for num in predictions.squeeze().values] #we convert the predictions to a list so it will be easier to compare with metrics with the real label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92645c0",
   "metadata": {},
   "source": [
    "Then we read the labels that were reserved in the data preparation in a local folder for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e467595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = pd.read_csv(f\"data_prepared_{version}/test_y.csv\",header = None) \n",
    "test_y = list(test_y[0]) #we transform the first column (not index) to a list so it will be compared with the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3030232",
   "metadata": {},
   "source": [
    "Now the results are compared by creating a confusion matrix out of the predictions vs the real labels. \n",
    "From the confusion matrix we can calculate the metric for classfication models. We use the tools in the sklearn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b94cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(test_y, predictions, labels=None, sample_weight=None, normalize=None)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91015b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels')\n",
    "ax.set_title(f'Confusion Matrix. Model : {version}')\n",
    "ax.xaxis.set_ticklabels(['Normal', 'Violent'])\n",
    "ax.yaxis.set_ticklabels(['Normal', 'Violent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print(f\"Model version: {version}\")\n",
    "print(\"Accuracy: \", accuracy_score(test_y, predictions))\n",
    "print(\"Precision: \", precision_score(test_y, predictions))\n",
    "print(\"Recall: \", recall_score(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152434d8",
   "metadata": {},
   "source": [
    "## 4. Combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f647c",
   "metadata": {},
   "source": [
    "We set the version variable for it will help us with file management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b52b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"combined\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c46999e",
   "metadata": {},
   "source": [
    "Here we load the location of the files on S3 that were uploaded for this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1318b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_location = combined[\"test\"] #the information is loaded from the .py file created in the data preparation step\n",
    "val_location = combined[\"val\"]\n",
    "train_location = combined[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc11e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix (which folder will we use)\n",
    "prefix = f'twitter_sentiment_{version}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d842af",
   "metadata": {},
   "source": [
    "### Set the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a SageMaker estimator object for our model.\n",
    "xgb_combined = sagemaker.estimator.Estimator(container, # The location of the container we wish to use\n",
    "                                    role,                                    # What is our current IAM Role\n",
    "                                    instance_count=1,                  # How many compute instances\n",
    "                                    instance_type='ml.m4.xlarge',      # What kind of compute instances\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "# And then set the algorithm specific parameters.\n",
    "xgb_combined.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d0495",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b633fb7",
   "metadata": {},
   "source": [
    "Set the training and validation data set on s3 to be used by sagemaker. This variables will let the model know where to find the information in S3 that will be used to estimate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cbb02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e8ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_combined.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed417ab3",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac8bed",
   "metadata": {},
   "source": [
    "For this part of the process a transformer object will be created. This is an object can be understood as a function that used the artifacts (betas) created by the model and then uses them to predict based in a new data set. \n",
    "The test dataset will be given to the transformer and the results will be compared to the actual labels that were reserved for the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ceafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a transformer object. This will use the artifacts created by the estimator to transform (create a prediction) using the testing dataset.\n",
    "xgb_combined_transformer = xgb_combined.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_combined_transformer.transform(test_location, content_type='text/csv', split_type='Line') \n",
    "#the location of the test set is passed to the transfomer to perform the transformation. (predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e001032",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_combined_transformer.wait() #we wait until the transformer is done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b385a9e",
   "metadata": {},
   "source": [
    "After the tranformation is done, we will specify a new folder where the results (the are created in a S3 folder) can be downloaded from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7504b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"results_{version}\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c892c4",
   "metadata": {},
   "source": [
    "Next, using the next command we download the predictions made by the transformer object into the local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f528613",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $xgb_combined_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ecc18a",
   "metadata": {},
   "source": [
    "Now the predictions are read with pandas into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None) #the header is none because the first line is a prediction and not the name of the column\n",
    "predictions = [round(num) for num in predictions.squeeze().values] #we convert the predictions to a list so it will be easier to compare with metrics with the real label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4ab6e",
   "metadata": {},
   "source": [
    "Then we read the labels that were reserved in the data preparation in a local folder for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = pd.read_csv(f\"data_prepared_{version}/test_y.csv\",header = None) \n",
    "test_y = list(test_y[0]) #we transform the first column (not index) to a list so it will be compared with the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ef8fd",
   "metadata": {},
   "source": [
    "Now the results are compared by creating a confusion matrix out of the predictions vs the real labels. \n",
    "From the confusion matrix we can calculate the metric for classfication models. We use the tools in the sklearn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ee7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(test_y, predictions, labels=None, sample_weight=None, normalize=None)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bac003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels')\n",
    "ax.set_title(f'Confusion Matrix. Model : {version}')\n",
    "ax.xaxis.set_ticklabels(['Normal', 'Violent'])\n",
    "ax.yaxis.set_ticklabels(['Normal', 'Violent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print(f\"Model version: {version}\")\n",
    "print(\"Accuracy: \", accuracy_score(test_y, predictions))\n",
    "print(\"Precision: \", precision_score(test_y, predictions))\n",
    "print(\"Recall: \", recall_score(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4424b",
   "metadata": {},
   "source": [
    "#### The combined approach is the one that maximizes the Recalll metric. Therefore, we will choose this model.\n",
    "We will save the name of the training job so it can be accessed later in the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb075898",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = xgb_combined._current_job_name\n",
    "print(type(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71704e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/training_job_AWS.json\", \"w\") as file:\n",
    "    json.dump({\"training_job\":training_job_name},file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
